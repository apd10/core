module: "Loop"
device_id: 6
epochs: 10
train_data:
  file: ""
  dataset: "running_race"
  running_race:
    underlying_data:
      file: "/home/apd10/experiments/projects/summary_based_learning/DATA/mnist/train.txt"
      dataset: "gensvm"
      gensvm:
        dimension: 784
      sampler: "simple"
      simple:
        batch_size: 100
    race:
      power: 10
      repetitions: 10
      num_classes: 10
      max_coord: 1
      min_coord: 0
      random_seed: 101
      ace_type: "cs"
      ace_params:
        rep : 1
        range : 1000
        num_keys : 10 # equal to the power
        device_id : -1 # to do on cpu. test device as well later
        sketch_type : "CMS" # we only store counts
        recovery : "min" # min recovery
        decay:
          half_life: 100
      lsh_function:
        name: "l2lsh_torch"
        l2lsh_torch:
          bandwidth: 0.5
          dimension: 784
          max_norm: 17
          device_id: -1
    skip_rows: 1000

  sampler: "simple"
  simple:
    batch_size: 64
progress_test_data:
  file: ""
  dataset: "running_race"
  running_race:
    underlying_data:
      file: "/home/apd10/experiments/projects/summary_based_learning/DATA/mnist/test.txt"
      dataset: "gensvm"
      gensvm:
        dimension: 784
      sampler: "simple"
      simple:
        batch_size: 100
    race:
      power: 10
      repetitions: 10
      num_classes: 10
      max_coord: 1
      min_coord: 0
      random_seed: 101
      ace_type: "cs"
      ace_params:
        rep : 1
        range : 1000
        num_keys : 10 # equal to the power
        device_id : -1 # to do on cpu. test device as well later
        sketch_type : "CMS" # we only store counts
        recovery : "min" # min recovery
        decay:
          half_life: 100
      lsh_function:
        name: "l2lsh_torch"
        l2lsh_torch:
          bandwidth: 0.5
          dimension: 784
          max_norm: 17
          device_id: -1
    skip_rows: 1000

  sampler: "simple"
  simple:
    batch_size: 64
model:
  name: "MLP"
  MLP:
    input_dim: 100
    num_layers: 3
    hidden_size: 100
    num_class: 10
optimizer:
  name: "adam"
  adam:
    lr: 0.001
    weight_decay: 0
loss:
  name: "NLL"
progress_evaluator:
  name: "simple_print"
  simple_print:
      eval_itr: 100000000
      eval_epoch: 1
